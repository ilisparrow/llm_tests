{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use cases\n",
    "\n",
    "#1 Competitor publications\n",
    "#2 Financial news for traders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import urllib.request\n",
    "import streamlit as st\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import json\n",
    "from dotenv import dotenv_values\n",
    "from googlesearch import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup env vars \n",
    "\n",
    "# take environment variables from .env.\n",
    "load_dotenv()\n",
    "\n",
    "# config = {\"USER\": \"foo\", \"EMAIL\": \"foo@example.org\"}\n",
    "env_vars = dotenv_values(\".env\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define system relevant input data for application\n",
    "HARD_LIMIT_CHAR = 10000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)\n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "\n",
    "def extract_json_values(input_str):\n",
    "    results = []\n",
    "    while input_str:\n",
    "        try:\n",
    "            value = json.loads(input_str)\n",
    "            input_str = \"\"\n",
    "        except json.decoder.JSONDecodeError as exc:\n",
    "            if str(exc).startswith(\"Expecting value\"):   \n",
    "                input_str = input_str[exc.pos+1:]\n",
    "                continue\n",
    "            elif str(exc).startswith(\"Extra data\"):\n",
    "                value = json.loads(input_str[:exc.pos])\n",
    "                input_str = input_str[exc.pos:]\n",
    "        results.append(value)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## User input data\n",
    "\n",
    "#TODO : DO URL Check and show message when not valid\n",
    "\n",
    "#Web Scrapping and UI\n",
    "#url_to_watch = st.text_input(\"Input your url here\",\"https://www.nytimes.com/international/section/politics\")\n",
    "url_to_watch = st.text_input(\"Input your url here\",\"https://laion.ai/blog/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable content saved to the file: output.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h1/dv77d0852z9ft3dtpr8r4bz00000gn/T/ipykernel_40566/3588807974.py:13: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  texts = soup.findAll(text=True)\n"
     ]
    }
   ],
   "source": [
    "## Process website and save content to file\n",
    "\n",
    "html = urllib.request.urlopen(url_to_watch).read()\n",
    "text_from_webpage = text_from_html(html)\n",
    "#TODO : Fixe this limit, in a smarter way\n",
    "text_from_webpage = text_from_webpage[:HARD_LIMIT_CHAR]\n",
    "\n",
    "# Logging\n",
    "file_path = \"output.txt\"\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(text_from_webpage)\n",
    "print(\"Variable content saved to the file:\", file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This request contained the following number of tokens: ~3456\n"
     ]
    }
   ],
   "source": [
    "# LLM part\n",
    "# if st.button('Analyze'):\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"webpage\"],\n",
    "    template=\"In this web page, can you find a pattern, list all the articles and their publication dates. Do not mix the date with the reading time. Limit yourself to the first 3. In Json format, using these keys \\\"title\\\", \\\"date\\\". No Other text. \\\n",
    "        webpage :  \\\"{webpage}\\\"\",\n",
    "    )\n",
    "prompt_to_send = prompt.format(webpage=text_from_webpage)\n",
    "\n",
    "\n",
    "# Count tokens in request\n",
    "tokens_total = (len(text_from_webpage) + len(prompt_to_send))/4\n",
    "print(\"This request contained the following number of tokens: ~\" + str(round(tokens_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=env_vars['OPENAI_API_KEY'],temperature=0.9)\n",
    "result_from_chatgpt = llm(prompt_to_send).replace(\"\\n\", \"\")\n",
    "print(result_from_chatgpt)\n",
    "file_path = \"gpt_out.txt\"\n",
    "\n",
    "parsed_articles = json.loads(result_from_chatgpt)\n",
    "#Logging\n",
    "file_path = \"output_gpt.txt\"\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(result_from_chatgpt)\n",
    "print(\"Variable content saved to the file:\", file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
